{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32737cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\uqkmuroi\\gitcode\\Torch-Practice\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'botorch.models.turbo'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mbotorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mturbo\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TurboState\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mbotorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01moptim\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m optimize_acqf\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mbotorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01macquisition\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m qExpectedImprovement\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'botorch.models.turbo'"
     ]
    }
   ],
   "source": [
    "# Trubo state is not a real package, but a method to find a trust region to help exploit a complex function. You can follow the tutorial on botorch to learn how to do this on a 20D Ackely function. But I'll leave this here for now\n",
    "\n",
    "from botorch.models.turbo import TurboState\n",
    "from botorch.optim import optimize_acqf\n",
    "from botorch.acquisition import qExpectedImprovement\n",
    "from botorch.models import SingleTaskGP\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "\n",
    "\n",
    "noise_level = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d54a2fdd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'noise_level' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mobjective_function\u001b[39m(X, pHopt =\u001b[32m7\u001b[39m, pHopt2 = \u001b[32m5.5\u001b[39m, temp_opt =\u001b[32m35\u001b[39m, temp_opt2=\u001b[32m30\u001b[39m,  a = \u001b[32m100\u001b[39m, b = \u001b[32m20\u001b[39m, c = \u001b[32m1\u001b[39m, noise_level = \u001b[43mnoise_level\u001b[49m, seed = \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m      2\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03m    Simulates a 2D Gaussian-like response surface with controllable noise.\u001b[39;00m\n\u001b[32m      4\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     13\u001b[39m \u001b[33;03m    - y: simulated noisy response values\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m     15\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m seed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mNameError\u001b[39m: name 'noise_level' is not defined"
     ]
    }
   ],
   "source": [
    "def objective_function(X, pHopt =7, pHopt2 = 5.5, temp_opt =35, temp_opt2=30,  a = 100, b = 20, c = 1, noise_level = noise_level, seed = None):\n",
    "    \"\"\"\n",
    "    Simulates a 2D Gaussian-like response surface with controllable noise.\n",
    "\n",
    "    Parameters:\n",
    "    - X: input tensor of shape [n, 2], columns are [pH, temp]\n",
    "    - pHopt, temp_opt: optimal pH and temperature\n",
    "    - a: peak value (must be high enough to keep output positive)\n",
    "    - b, c: curvature coefficients (bigger = narrower peak)\n",
    "    - noise_level: fraction of y to scale the noise (e.g., 0.1 = 10%)\n",
    "\n",
    "    Returns:\n",
    "    - y: simulated noisy response values\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        torch.manual_seed(seed) # set for reproducibility\n",
    "    pH, temp = X[:, 0], X[:, 1]\n",
    "\n",
    "     # First peak at (pH=7, temp=35)\n",
    "    pH_term1 = torch.exp(-0.5 * ((pH - pHopt) / 1.5)**2)  # Gaussian term for pH with width 1.5\n",
    "    temp_term1 = torch.exp(-0.5 * ((temp - temp_opt) / 5.0)**2)  # Gaussian term for temp with width 5.0\n",
    "\n",
    "    # Second peak at (pH=5.5, temp=30)\n",
    "    pH_term2 = torch.exp(-0.5 * ((pH - pHopt2) / 1.5)**2)\n",
    "    temp_term2 = torch.exp(-0.5 * ((temp - temp_opt2) / 5.0)**2)\n",
    "\n",
    "     # Stronger Sinusoidal Modulation\n",
    "    sin_component = torch.sin(2 * pH) * torch.cos(1.5 * temp)  # Higher frequency\n",
    "    wave_strength = 1.5  # Scale up the wave effect\n",
    "\n",
    "    # Combine the two peaks with the stronger sinusoidal variation\n",
    "    y = (pH_term1 * temp_term1 + pH_term2 * temp_term2) * (1 + wave_strength * sin_component)\n",
    "\n",
    "    noise = noise_level * torch.randn_like(y) # changed this here from Isabella's to make noise homoscedastic (same for all points)\n",
    "    return y + noise\n",
    "'''\n",
    "# generates initial sample using latinhypercube\n",
    "g=torch.Generator().manual_seed(42) # ensure's results are same each time\n",
    "train_X = maximin_lhs(initial_sample, bounds, generator=g) # this will be consistent as we set the seed at beginning\n",
    "'''\n",
    "# above is broken, below is temp fix\n",
    "train_X = scaled_lhs_design\n",
    "# generates solution for initial sample using objective function\n",
    "train_Y= objective_function(train_X, seed=seed) # add seed=seed here if you want obj func to always spit out the same answer. Removing it will simulate biological variability. Usually not necessary for initial run unless samples repeated.\n",
    "train_Y = train_Y.unsqueeze(-1) # reshape to (n, 1) (from (n,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce14c89",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2431776247.py, line 11)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mtrain_X, train_Y = <your small data set>\u001b[39m\n                       ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Turbo MODEL\n",
    "\n",
    "\n",
    "# Fit initial GP\n",
    "gp = SingleTaskGP(train_X, train_Y)\n",
    "mll = ExactMarginalLogLikelihood(gp.likelihood, gp)\n",
    "fit_gpytorch_model(mll)\n",
    "\n",
    "# Set up TuRBO state\n",
    "turbo_state = TurboState(\n",
    "    dim=train_X.shape[-1],\n",
    "    batch_size=1,\n",
    "    length_init=0.8,  # large init trust region\n",
    "    success_tolerance=3,\n",
    "    failure_tolerance=3,\n",
    ")\n",
    "\n",
    "# Main loop\n",
    "for iteration in range(MAX_ITERS):\n",
    "    if turbo_state.restart_triggered:\n",
    "        turbo_state = TurboState(dim=train_X.shape[-1], batch_size=1)\n",
    "\n",
    "    # Define acquisition function\n",
    "    acq = qExpectedImprovement(model=gp, best_f=train_Y.max(), maximize=True)\n",
    "\n",
    "    # Optimize in trust region\n",
    "    candidates, _ = optimize_acqf(\n",
    "        acq_function=acq,\n",
    "        bounds=turbo_state.get_bounds(train_X),\n",
    "        q=1,\n",
    "        num_restarts=5,\n",
    "        raw_samples=100,\n",
    "    )\n",
    "\n",
    "    # Evaluate candidate (real experiment)\n",
    "    new_Y = objective_function(candidates)\n",
    "\n",
    "    # Update data\n",
    "    train_X = torch.cat([train_X, candidates], dim=0)\n",
    "    train_Y = torch.cat([train_Y, new_Y], dim=0)\n",
    "\n",
    "    # Update model\n",
    "    gp.set_train_data(train_X, train_Y, strict=False)\n",
    "    fit_gpytorch_model(ExactMarginalLogLikelihood(gp.likelihood, gp))\n",
    "\n",
    "    # Update TuRBO trust region\n",
    "    turbo_state.update(train_Y[-1])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
