{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\uqkmuroi\\gitcode\\Torch-Practice\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 34\u001b[39m\n\u001b[32m     31\u001b[39m     noise = noise_level * y * torch.randn_like(y)\n\u001b[32m     32\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m y + noise\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m model = SingleTaskGP(\u001b[43mX\u001b[49m, y, input_transform = Normalize(d=\u001b[32m2\u001b[39m), outcome_transform = Standardize(m=\u001b[32m1\u001b[39m))\n\u001b[32m     35\u001b[39m mll = ExactMarginalLogLikelihood(model.likelihood, model)\n\u001b[32m     36\u001b[39m fit_gpytorch_mll(mll)\n",
      "\u001b[31mNameError\u001b[39m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "#Bayesian Optimization using Gaussian Processes for Hyperparameter Tuning with noisy experimental data.\n",
    "\n",
    "import torch\n",
    "from botorch.models import SingleTaskGP\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from botorch.models.transforms import Standardize, Normalize\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "def objective_function(X, pHopt =7 , temp_opt =35, a = 100, b = 1, c = 1, noise_level = 0.1):\n",
    "    \"\"\"\n",
    "    Simulates a 2D Gaussian-like response surface with controllable noise.\n",
    "\n",
    "    Parameters:\n",
    "    - X: input tensor of shape [n, 2], columns are [pH, temp]\n",
    "    - pHopt, temp_opt: optimal pH and temperature\n",
    "    - a: peak value (must be high enough to keep output positive)\n",
    "    - b, c: curvature coefficients (bigger = narrower peak)\n",
    "    - noise_level: fraction of y to scale the noise (e.g., 0.1 = 10%)\n",
    "\n",
    "    Returns:\n",
    "    - y: simulated noisy response values\n",
    "    \"\"\"\n",
    "    pH, temp = X[:, 0], X[:, 1]\n",
    "    y = a-b*(pH-pHopt)**2 - c*(temp-temp_opt)**2\n",
    "    noise = noise_level * y * torch.randn_like(y)\n",
    "    return y + noise\n",
    "\n",
    "model = SingleTaskGP(X, y, input_transform = Normalize(d=2), outcome_transform = Standardize(m=1))\n",
    "mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "fit_gpytorch_mll(mll)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class GPWithNoise:\n",
    "    def __init__(self, X, Y, kernel, noise_variance=0.1, y_norm='meanstd', opt_params=None):\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.y_norm = y_norm\n",
    "        self.opt_params = opt_params if opt_params else {}\n",
    "        \n",
    "        self.Y_mean = Y.mean() if y_norm == 'meanstd' else 0\n",
    "        self.Y_std = Y.std() if y_norm == 'meanstd' else 1\n",
    "        \n",
    "        self.model = self._create_gp_model(X, Y, kernel, noise_variance)\n",
    "        self.mll = ExactMarginalLogLikelihood(self.model.likelihood, self.model)\n",
    "        \n",
    "    def _create_gp_model(self, X, Y, kernel, noise_variance):\n",
    "        Y_norm = (Y - self.Y_mean) / self.Y_std if self.y_norm == 'meanstd' else Y\n",
    "        likelihood = gpytorch.likelihoods.GaussianLikelihood(noise_constraint=gpytorch.constraints.Positive())\n",
    "        \n",
    "        # Set initial value of noise (learnable parameter)\n",
    "        likelihood.noise = torch.tensor(noise_variance, dtype=torch.float32, requires_grad=True)\n",
    "        \n",
    "        model = SingleTaskGP(X, Y_norm.unsqueeze(-1), likelihood=likelihood)\n",
    "        return model.to(self.device)\n",
    "    \n",
    "    def optimize(self, steps=100):\n",
    "        # Create the Adam optimizer\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=0.1)\n",
    "        \n",
    "        for _ in range(steps):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            output = self.model(self.model.train_inputs[0])\n",
    "            loss = -self.mll(output, self.model.train_targets)\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    def get_acquisition_function(self, acq_type, best_f=None):\n",
    "        if acq_type == 'EI':\n",
    "            return ExpectedImprovement(self.model, best_f=best_f)\n",
    "        elif acq_type == 'UCB':\n",
    "            return UpperConfidenceBound(self.model, beta=2.0)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported acquisition function\")\n",
    "    \n",
    "    def predict(self, X_new):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            return self.model(X_new)\n",
    "\n",
    "# Example usage:\n",
    "# X and Y are your training data (torch tensors)\n",
    "# You might have a custom kernel defined already\n",
    "X_train = torch.rand(10, 1)  # Example training inputs\n",
    "Y_train = torch.sin(X_train) + 0.1 * torch.randn(10, 1)  # Noisy observations (y = sin(x) + noise)\n",
    "Y_train = Y_train.squeeze()\n",
    "\n",
    "# Define a simple kernel (RBF, or any custom kernel)\n",
    "kernel = gpytorch.kernels.RBFKernel()\n",
    "\n",
    "gp_model = GPWithNoise(X_train, Y_train, kernel)\n",
    "\n",
    "# Perform optimization\n",
    "gp_model.optimize(steps=100)\n",
    "\n",
    "# Example prediction (new data)\n",
    "X_new = torch.rand(5, 1)\n",
    "predictions = gp_model.predict(X_new)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
